---
title: "统计学习中"
author: "wangbinzjcc@qq.com"
date: "Friday, January 09, 2015"
output: 
  ioslides_presentation:
        logo: F:/rmarkdown/gxib0.png
---
```{r,echo=FALSE, message=FALSE}
require(knitr)
opts_chunk$set(cache=F)
```

## 概念

**数理统计:**   


以**概率论**为基础, 通过分析**观察数据**, 来研究**随机现象**, 以估计和推断出**客观规律**为目的, 的数学学科分支.

## 关键词
  随机事件, 伯努利事件;
  
  二项分布, 大数定律, 正态分布, 极限中心定律;  
   
  期望, 方差, 峰度, 偏度, 协方差, 相关系数;  
  
  X2分布, t分布, F分布;
  
  假设检验, 两类错误, X2检验, t检验, F检验;  
  
  最小二乘法, 距法, 极大似然法;
  
  区间估计;
  
  方差分析, 线性回归
 
## 定义: 随机事件
  **随机现象**: 在一定条件下, 所得结果不能预先完全确定, 而只能确定是多种可能结果中的一种, 称这种现象为随机现象.  
  
  **随机试验**: 随机现象得以实现,且被观察记录的全过程称为随机试验.  
  
  **随机事件**: 随机试验的所有可能结果组成的集合为样本空间, 每一个可能结果称为样本点, 称样本空间中一定条件的子集(样本点集合)为随机事件.
  
## 定义: 概率
  **概率**: 随机试验$E$的样本空间为$\Omega$, $(\Omega,F)$是可测空间, 对于每个事件$A\in F$, 定义一个实数$P(A)$与之对应, 若函数$P(.)$满足条件:  
  1. 对每个事件$A$均有$0<P(A)<1$;  
  2. $P(\Omega)=1$;  
  3. 若事件$A1,A2,...$两两互斥;即对于$i,j=1,2,...$, $i\neq j$, $A_iA_j=\phi$, 均有$P(A1\cup A2\cup ...)=$$P(A1)+P(A2)+ ...$;  
  则称$P(A)$为事件$A$的概率, 称$(\Omega,F,P)$为概率空间.  

## 定义: 独立事件 条件概率
  **独立事件**: 若两事件$A,B$的积事件发生概率等于这两个事件概率的乘积, 即$P(A\cap B)=P(A)P(B)$, 则称事件$A$与事件$B$是相互独立的(mutually independent).  
   
  **条件概率**: 设$A$和$B$是两个事件, 且$P(B)>0$, 称$P(A|B)=$$P(A\cap B)/P(B)$为在事件$B$发生的条件下, 事件$A$发生的条件概率(conditional probability).
  
## 定义: 二项分布
**伯努利试验**: 如果一个随机试验只有两种可能的结果$A$和$\bar{A}$ , 并且$P(A)=p$ , $P(\bar{A})=1-p=q$ , 其中$0<p<1$ , 则称此试验为Bernoulli(伯努利)试验.

**n重伯努利试验**: Bernoulli试验独立重复进行n次, 称为n重Bernoulli试验.

**二项分布**: 从一批产品中检测次品$A$, 在其中进行有放回抽样n次, 抽到次品$A$称为“成功”, 抽到正品$\bar{A}$称为“失败”, 这就是n重Bernoulli试验.设$A_k=$$\{n重Bernoulli试验中A出现k次\}$ , 则$P(A_k)=$$C^k_n P^k (1-p)^{n-k}$ , $k=0,1,2,...,n$ . 这就是著名的二项分布, 常记作$B(n,k)$ .

## R语言: 伯努利分布 与 二项分布
```{r}
rbinom(n=10, size=1, prob=0.5)  # 二点分布(Bernoulli分布)
rbinom(n=10, size=100, prob=0.5)# 二项分布(100重bernoulli分布)
```

## 定义: 泊松分布
**Poisson分布**:   
令$P_n$为n重Bernoulli试验中事件$A$出现的概率, 且$\lambda=nP_n$ ;  
那么, 当$n \to \infty$ 且$P_n \to 0$时, 有$C^k_n P^k_n (1-P_n)^{n-k} \approx$ $\frac{\lambda ^k e^{-\lambda}}{k!}$ , 此时二项分布可以用Poisson分布来近似代替. 

## R语言: 二项分布 与 泊松分布
 当size很大且prob很小时, **二项分布**dbinom(x, size, prob)可以用**泊松分布**dpois(x, lambda)来近似代替.
```{r, echo=FALSE}
layout(matrix(1:3,nrow=3))
par(mex=0.6,mar=c(2.5,5,5,1))

from=10
to=30
plot(x=from:to, y=dbinom(from:to, size = 40, prob=0.5), type='l',lty=1, lwd=5, col=3, xlab='', ylab='p-value', main='size=40, prob=0.5, lambda=size*prob')
points(x=from:to, y=dpois(from:to, lambda=40 * 0.5), type='l',lty=2, lwd=2, col=2)
legend(x=25,y=0.10,legend=c('dbinom()','bposi()'),lty=c(1,2), lwd=c(5,2), col=c(3,2), bty='n')

from=49500
to=50500
plot(x=from:to, y=dbinom(from:to, size = 1e+5, prob=0.5), type='l', lty=1, lwd=5, col=3, xlab='', ylab='p-value', main='size=1e+5, prob=0.5, lambda=size*prob')
points(x=from:to, y=dpois(from:to, lambda=1e+5 * 0.5), type='l',lty=2, lwd=2, col=2)
legend(x=50250,y=0.0025,legend=c('dbinom()','bposi()'),lty=c(1,2), lwd=c(5,2), col=c(3,2), bty='n')

from=10
to=30
plot(x=from:to, y=dbinom(from:to, size = 1e+5, prob=0.0002), type='l', lty=1, lwd=5, col=3, xlab='', ylab='p-value', main='size=1e+5, prob=0.0002, lambda=size*prob')
points(x=from:to, y=dpois(from:to, lambda=1e+5 * 0.0002), type='l', lty=2, lwd=2, col=2)
legend(x=25,y=0.08,legend=c('dbinom()','bposi()'),lty=c(1,2), lwd=c(5,2), col=c(3,2), bty='n')
```

## 定义: 大数定律
**大数定律**: 设$X_1,X_2,...,X_k,...$是随机变量序列, 且$E(X_k)$存在$(k=1,2,...)$, 令$Y_n=\frac{1}{n}\sum_{k=1}^{n}X_k$, 若对于任意给定的$\varepsilon>0$, 有$\underset{n \to \infty}P\{|Y_n - E(Y_n)|<\varepsilon\}=1$, 则称随机变量序列$X_k$服从大数定律. 即:大样本平均值无限逼近总体平均值.

## R语言: 大数定律
右偏型随机数据集random value的总体平均值为TotalMean.随机抽取样本量为number of sample,样本平均值为SampleMean.随着抽取样本量逐渐增大,总体平均值 - 样本平均值无限逼近0.
```{r, echo=FALSE}
nn=10000
i=1:nn
rR <- rbeta(nn,5,2)
MinusMean <- replicate(n=5,mean(rR)- cumsum(sample(x=rR))/i)
layout(matrix(1:2,nrow=2))
par(mar=c(3,4,2,1),las=1)
hist(rR, xlab='',main='Right Skewed Distribution')
title(xlab="random value", line= 1.8)

plot(rep(i,times=5), c(MinusMean) ,pch='*', ylim=c(-0.15, 0.15),main="TotalMean - SampleMean",xlab='')
title(xlab="number of sample", line= 1.8)
abline(h=0, col=2)

```

## 定义:  概率密度 
**概率密度**:   
对于随机变量X, 如果存在一个定义在$(-\infty,+\infty)$上的非负函数f(x), 使得对于任意实数x, 总有$F(x)=P\{X \leq x\}=\int_{-\infty}^x f(t)dt$, $-\infty < x < +\infty$, 则称X为连续型随机变量, f(x)为X的概率密度函数(probability density function), 简称概率密度.    
概率密度函数有如下性质:  
1. $\int_{-\infty}^{+\infty}f(x)dx=1$;   
2. 对任意实数$a,b(a<b)$,都有$P\{a<X\leq b\}=\int_a^b f(x)dx$;    
3. 若f(x)在点x处连续,则$f(x)=F’(x)$;   
4. 对任意实数a,总有$P\{X=a\}=0$.  


## 定义:  正态分布 
**正态分布**:
若随机变量X的概率密度函数为$f(x)=\frac{1}{\sqrt{2\pi}\sigma}exp\{-\frac{(x-\mu)^2}{2\sigma^2}\}$, $-\infty <x <+\infty$, 其中$\mu$, $\sigma(\sigma>0)$是两个常数, 则称X服从参数为$\mu$, $\sigma$的正态分布(Normal distribution), 也称为Gauss分布, 记作$X \sim N(\mu,\sigma^2)$ .
```{r, echo=FALSE, out.width=800, out.height=320}
sd=1
nx <- -400:400/100
dx <- dnorm(x = nx, mean = 0, sd = sd)
## 
layout(mat=matrix(1:2,nrow = 1,ncol = 2))
par(tck=0.02,las=1,mar=c(3,5,4,1),mex=0.7)
plot(nx, dx, type='l', xlab='r',ylab='p',xaxt='n',col=4,ylim=c(0,0.45), main='Probability density function')
grid()
rug(x=c(-3,3),ticksize=0.51,side=1 )
rug(x=c(-2,2),ticksize=0.31,side=1 )
rug(x=c(-1,1),ticksize=0.15,side=1 )
axis(side=1,at=-4:4,labels=-4:4)
arrows(x0=c(-3:0), y0=c(0.2,0.1,0.03,-0.1),
       x1=c(3:0), y1=c(0.2,0.1,0.03,0.46), length=0.15,
       angle= 20, code=3 )
text(x=c(0.5,-0.5,0.5),y=c(0.21,0.11,0.04),
     labels = c('99.7%','95.4%','68.3%'),col=3)
text(2, 0.35, 'sd = 1',cex=1.2,col=4)
## 
px <- pnorm( nx, mean = 0, sd = sd)
plot(nx, px, type='l', xlab='r',ylab='p',col=4,ylim=c(0,1), main='Probability cumulative function')
grid()
abline(v=0, h=0.5, lty=3,col=2)

```

## 定义:  正态分布的性质

 如果$X \sim N(\mu, \sigma^2) \,$且$a$与$b$是实数，那么$a X + b \sim N(a \mu + b, (a \sigma)^2)$ .   
 
 如果$X \sim N(\mu_X, \sigma^2_X)$与$Y \sim N(\mu_Y, \sigma^2_Y)$是独立的正态随机变量，那么:    
* 他们的和也满足正态分布$U = X + Y \sim N(\mu_X + \mu_Y, \sigma^2_X + \sigma^2_Y)$.  
* 他们的差也满足正态分布$V = X - Y \sim N(\mu_X - \mu_Y, \sigma^2_X + \sigma^2_Y)$.  
* $U$与$V$两者是相互独立的.(要求X与Y的方差相等)  

## 定义:  正态分布的性质
 如果$X \sim N(0, \sigma^2_X)$和$Y \sim N(0, \sigma^2_Y)$是独立的正态随机变量，那么:   
* 他们的积$X Y$服从概率密度为$p$的分佈.    
* $p(z) = \frac{1}{\pi\,\sigma_X\,\sigma_Y} \; K_0\left(\frac{|z|}{\sigma_X\,\sigma_Y}\right),$其中$K_0$是修正贝塞尔函数(modified Bessel function)   
* 他们的比符合柯西分佈，满足$X/Y \sim \mathrm{Cauchy}(0, \sigma_X/\sigma_Y)$.      
* 如果$X_1, \cdots, X_n$为独立标准正态随机变量，那么$X_1^2 + \cdots + X_n^2$服从自由度为'n'的卡方分布.  

## 定义:  正态分布的加法
 如果$X \sim N(0, 1^2)$与$Y \sim N(1, 2^2)$是独立的正态随机变量，那么: 他们的和也满足正态分布$U = X + Y \sim N(0+ 1, 1^2 + 2^2)$$\sim N(1, 2.236^2)$.  
```{r, echo=FALSE, out.width=800, out.height=320}
layout(mat=matrix(1:3,nrow = 1))
par(tck=0.02,las=1,mar=c(3,5,4,1),mex=0.7)
X <- rnorm(n = 10000, mean = 0, sd = 1)
Y <- rnorm(n = 10000, mean = 1, sd = 2)
U <- X + Y
hist(X, breaks=20, probability = T, xlim=c(-8,8))
abline(v=c(-1,0,1), col=c(3,2,3))
hist(Y, breaks=50, probability = T, xlim=c(-8,8))
abline(v=c(1-2,1,1+2), col=c(3,2,3))
hist(U, breaks=50, probability = T, xlim=c(-8,8))
abline(v=c(1-2.236,1,1+2.236), col=c(3,2,3))
## 
```

## 定义: 中心极限定律
**中心极限定律**:  
自然界中一些现象受到许多相互独立随机因素的影响, 如果每个因素的影响都很小, 那么总的影响可以看作是服从正态分布.中心极限定理是从数学上论证这一现象, 判断随机变量序列部分和的分布是否渐近于正态分布的一类定理. 

## 定义: 中心极限定律
**独立同分布的中心极限定理**:   
设随机变量$X_1, X_2, \cdot\cdot\cdot, X_k, \cdot\cdot\cdot$相互独立, 服从同一分布, 并有期望和方差$E(X_k)=\mu$ , $Var(X_k)=\sigma^2>0$ , $k=1,2,\cdot\cdot\cdot$ , 则随机变量$Y_n=\frac{\sum_{k=1}^{n}X_k - n\mu}{\sqrt{n}\sigma}$的分布函数$F_n(x)$收敛到标准正态分布函数, 即对任意实数x, 有$\underset{n \to \infty}{lim}F_n(x)=$$\underset{n \to \infty}P\{Y_n \leq x\}=$$\Pi(x)$ , 其中$\Pi(x)=$$\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{t^2}{2}}dt$ .   
**由中心极限定理可知, 当n足够大时, $Y_n$近似服从标准正态分布N(0,1), 这在数理统计中有重要的应用.**

## R语言: 中心极限定律
有样本总量为nTotal=10000, 平均值为$\mu$的右偏型随机数据集random value, 从中随机抽取样本量为n=1000的数值$X_k$, 求$(\sum_{k=1}^{n}X_k - n\mu )/ (\sqrt{n}\sigma)$, 并重复计算replicate=10000次.
```{r, echo=FALSE}
nn=10000
i=1:nn
rR <- rbeta(nn,5,2)
TotalMean=mean(rR)
TotalVar =var(rR)
YnFunc<-function(n.s){(sum(sample(x=rR)[1:n.s]) - n.s*TotalMean)/sqrt(n.s*TotalVar)}

layout(matrix(1:2,nrow=2))
par(mar=c(4.5,5,2,1),las=1,mex=0.7)
hist(rR,breaks = 100,probability=T,main='Histogram of right skewed distribution', xlab="random value")
lines(density(rR), col="red")

repYn <- replicate(n=10000, YnFunc(n.s=1000))
hist(repYn,breaks = 100, probability=T, main='n=1000, nTotal=10000, Replicate=10000', xlab=expression((sum(X[1:n])- n * mu)/(sqrt(n) * sigma)))
lines(density(repYn), col="red")
plot(function(x){exp(-x^2/2)/sqrt(2*pi)},-3,3,add=T,col=4)
legend(1.2,0.35,c( 'sample density', 'normal distribution'),col=c(2,4),bty='n',lty=1)
```

## 定义:  期望
**期望**: $~ E(X) = sum(X_i \ast P_i) = mean(X)$  
1. 若c是常数, 则E(c)=c;  
2. E(aX+bY) = aE(X) + bE(Y), 其中a,b为任意常数;  
3. 若X,Y相互独立, 则E(XY)=E(X)E(Y).  

## 定义:  方差
**方差**: $~ var(X) = E\{[X-E(X)]^2\}$  
1. 若c是常数, 则var(c)=0;  
2. $var(aX+b)=a^2 var(X)$, 其中a,b为任意常数;  
3. 如果X,Y相互独立, 则var(X + Y) = var(X) + var(Y);  
4. $var(X)=E(X^2)-[E(X)]^2$.  

## 定义:  协方差
**协方差**: $~cov = E\{[X-E(X)][Y-E(Y)]\}$  
1. $cov(X,Y) = cov(Y,X)$ ;  
2. $cov(aX+b,cY+d) = ac~cov(X,Y)$ , a,b,c,d为任意常数;  
3. $cov(X_1+X_2,Y) = cov(X_1,Y)+cov(X_2,Y)$ ;  
4. $cov(X,Y) = E(XY)-E(X)E(Y)$ ;  
5. X和Y相互独立时, $cov(X,Y) = 0$ ;  
6. $|cov(X,Y)| \leq \sqrt{var(X)~var(Y)}$ ;  
7. $cov(X,X) = var(X)$ .

## 定义: 相关系数
**相关系数**: $~p(X,Y) = \frac{cov(X,Y)}{\sqrt{var(X)var(Y)}}$  
1. $|p(X,Y)|\leq 1$  
2. 若X与Y相互独立且$var(X)$,$var(Y)$存在,则$p(X,Y)=0$ .  

 
## 定义: $\chi^2$分布
**$\chi^2$分布**: $~$设$X_1,X_2,\cdot\cdot\cdot,X_n$是来自总体N(0,1)的一个简单样本, 则称统计量$Y=X_1^2+X_2^2+\cdot\cdot\cdot+X_n^2$为服从自由度为n的$\chi^2$分布(chi-square distribution), 记为$Y\sim\chi^2(n)$.  
$\chi^2$分布具有如下性质:  
1. 可加性. 设$Y_1\sim\chi^2(m)$, $Y_2\sim\chi^2(n)$,且两者相互独立,则$Y_1+Y_2\sim\chi^2(m+n)$ .  
2. 期望值与方差. 若$Y\sim\chi^2(n)$ , 则$E(Y)=n$, $var(Y)=2n$.


## 定义: $\chi^2$分布
卡方分布的**概率密度函数**为:  
$$f_k(x)=\frac{(1/2)^{k/2}}{\Gamma{(k/2)}}x^{k/2-1}e^{-x/2} ,其中x\geq 0 ;$$ 当$x\leq 0$时$f_k(x)=0$. 这里$\Gamma$代表Gamma函数.  

卡方分布的**累计分布函数**为:  
$$F_{k}(x)={\frac {\gamma (k/2,x/2)}{\Gamma (k/2)}} ,$$  其中$\gamma(k, z)$为不完全Gamma函数.

## R语言: $\chi^2$分布
卡方分布: $Y=X_1^2+X_2^2+\cdot\cdot\cdot+X_n^2$
```{r, echo=FALSE, out.width=800, out.height=400}

#
layout(matrix(1:2,nrow=1),widths = c(4,4) )
par(mar=c(4.5,5,5,1),las=1,mex=0.7)
X <- seq(0.001,50,length=100)
plot(x=X, y=dchisq(x=X, df=1),cex=0.6, type='o',xlab='y',ylab='density', xlim=c(0, 40), ylim=c(0, 0.4), main='probability density function \n with different freedom')
points(x=X, y=dchisq(x=X, df=4),cex=0.6,  type='o',col=2,pch=2)
points(x=X, y=dchisq(x=X, df=10), cex=0.6, type='o',col=3,pch=8)
points(x=X, y=dchisq(x=X, df=15), cex=0.6, type='o',col=4,pch=9)
legend(13, 0.38, c('n = 1', 'n = 4', 'n = 10', 'n = 15'), pch=c(1,2,8,9), bty='n', col=c(1,2,3,4),lty=1)
#
plot(x=X, y=pchisq(q=X, df=1), cex=0.6, type='o',xlab='y',ylab='density', xlim=c(0, 40), ylim=c(0,1), main='probability cumulative function \n with different freedom')
points(x=X, y=pchisq(q=X, df=4), cex=0.6, type='o',col=2,pch=2)
points(x=X, y=pchisq(q=X, df=10), cex=0.6, type='o',col=3,pch=8)
points(x=X, y=pchisq(q=X, df=15), cex=0.6, type='o',col=4,pch=9)
legend(13, 0.38, c('n = 1', 'n = 4', 'n = 10', 'n = 15'), pch=c(1,2,8,9), bty='n', col=c(1,2,3,4),lty=1)
```

## R语言: 为啥$E\{\chi^2(n=df)\}=df$
概率密度图形中的曲线峰值,位于直线df=x上.  
概率累积图形中 p=0.5数值, 位于直线df=x上.  
所以, $E\{\chi^2(n=df)\}=df$
```{r, echo=FALSE, out.height=350, out.width=800}
layout(matrix(1:2, nrow=1), widths = c(4,4) )  
par(mar=c(5,5,5,1), mex=0.5)
dat <- outer(X=seq(from=0.01,to=50,length=101), Y=1:50,
                          function(X,Y)dchisq(x=X,df=Y))
image(x=(0:100+1)/2, y=1:50, z=dat, xlab='x', ylab='df',main='probability density function')
contour(x=(0:100+1)/2, y=1:50, z=dat, 
       levels=round(seq(0, 0.5, length=100), 3),
        add=TRUE, col=4)
grid()
abline(a= 1, b=1, col=3, lwd=2)
#
dat <- outer(X=seq(from=0.01,to=50,length=101), Y=1:50,
                          function(X,Y)pchisq(q=X,df=Y))
image(x=(0:100+1)/2, y=1:50, z=dat,xlab='x',ylab='df',main='probability cumulative function')
contour(x=(0:100+1)/2, y=1:50, z=dat, 
       levels=round(seq(0, 1, length=30),3),
        add=TRUE, col=4)
grid()
abline(a=0, b=1, col=3, lwd=2)
```

 
## 定义: $t$分布
**t分布**: $~$设$X\sim N(0,1)$, $Y\sim \chi^2(n)$, 且X,Y相互独立，则称随机变量$T=\frac{X}{\sqrt{Y/n}}$
为服从自由度为n的t分布(t-distribution), 记为$T\sim t(n)$.

t分布的概率密度函数为:
$f(t)={\frac {\Gamma ((\nu +1)/2)}{{\sqrt {\nu \pi \,}}\,\Gamma (\nu /2)}}(1+t^{2}/\nu )^{{-(\nu +1)/2}}$
$\nu$等于n − 1, 一般被称为自由度.$\Gamma$是伽玛函数.

## 定义: $t$分布
设$X\sim N(0,1)$, $Y\sim \chi^2(n)$, 则$T=\frac{X}{\sqrt{Y/n}}$$\sim t(n)$.
```{r, echo=FALSE}
layout(matrix(1:6,nrow=2, byrow=T),widths = c(1,1,1) )
par(mar=c(5,8,1,1), mex=0.7)
df2=2
rnorm0 <- rnorm(n=10000)
rX2.df2 <- rchisq(n=10000,df=df2)
plot(rnorm0, ylim=c(-10, 10),pch='.',
     ylab= 'X=rnorm(n,0,1)') 
abline(h=c(0, mean(abs(rnorm0))), col=c(3,2))
legend(x=2000, y=-2, c('0-value','mean(abs(x))'),col=c(3,2),lty=1,bty='n',text.col=c(3,2))
plot(rX2.df2, ylim=c(-10, 10),pch='.',
     ylab= expression(chi^2*(n)*' ; n=2'))
abline(h=c(0,2), col=c(3,2))
legend(x=2000, y=-2, c('0-value','mean(x)'),col=c(3,2),lty=1,bty='n',text.col=c(3,2))
plot(rX2.df2/df2, ylim=c(-10, 10),pch='.',
     ylab= expression(chi^2*(n)/n*' ; n=2')) 
abline(h=c(0,1), col=c(3,2))
legend(x=2000, y=-2, c('0-value','mean(x)'),col=c(3,2),lty=1,bty='n',text.col=c(3,2))
plot(sqrt(rX2.df2/df2), ylim=c(-10, 10),pch='.',
     ylab= expression(sqrt(chi^2*(n)/n)*' ; n=2')) 
abline(h=c(0,mean(sqrt(rX2.df2/df2))), col=c(3,2))
legend(x=2000, y=-2, c('0-value','mean(x)'),col=c(3,2),lty=1,bty='n',text.col=c(3,2))
plot(rnorm0/sqrt(rX2.df2/df2), ylim=c(-10, 10),pch='.',
     ylab= expression('T=' * X/sqrt(chi^2*(n)/n)*' ; n=2')) 
abline(h=c(0,mean(abs(rnorm0/sqrt(rX2.df2/df2)))), col=c(3,2))
legend(x=2000, y=-2, c('0-value','mean(abs(x))'),col=c(3,2),lty=1,bty='n',text.col=c(3,2))
hist(rnorm0/sqrt(rX2.df2/df2), probability = T,ylim=c(0,0.4),main='',breaks = 500,xlim=c(-6,6),xlab='T(n); n=2')
curve(dt(x,df=df2),-5,5,add=T,col=2)
curve(dnorm(x),-5,5,add=T,col=4)
legend(x=-0.3, y=0.41, c('dnorm(x)','dt(x, df=2)'), lty=1,col=c(4,2), bty='n', text.col=c(4,2) )
abline(v=0,col=3,lwd=2)
```

## R语言: 为啥n > 30时dt() -> dnorm()
当n=df>30是t分布函数趋近于正态分布函数.
```{r, echo=FALSE, out.width=800, out.height=400}
#
layout(matrix(1:2,nrow=1),widths = c(4,4) )
par(mar=c(5,5,5,1), mex=0.5)
X <- seq(-5,5,length=50)
plot(x=X, y=dt(x=X, df=1), type='o', cex=0.7,xlab='T-value',ylab='density', xlim=c(-5, 5), ylim=c(0, 0.4), main='probability density function \n with different freedom')
points(x=X, y=dt(x=X, df=2), type='o', cex=0.7,col=2,pch=2)
points(x=X, y=dt(x=X, df=5), type='o', cex=0.7,col=3,pch=8)
points(x=X, y=dt(x=X, df=25), type='o', cex=0.7,col=4,pch=0)
points(x=X,y=dnorm(x=X),type='l',col=5, lwd=2)
legend(1.5, 0.38, c('n = 1', 'n = 2', 'n = 5', 'n = 25','dnorm()'), pch=c(1,2,8,0,20), bty='n', col=c(1,2,3,4,5), lty=1)
#
plot(x=X, y=pt(q=X, df=1), type='o', cex=0.7,xlab='T-value',ylab='density', xlim=c(-5, 5), ylim=c(0,1), main='probability cumulative function \n with different freedom')
points(x=X, y=pt(q=X, df=2), type='o', cex=0.7,col=2,pch=2)
points(x=X, y=pt(q=X, df=5), type='o', cex=0.7,col=3,pch=8)
points(x=X, y=pt(q=X, df=25), type='o', cex=0.7,col=4,pch=0)
points(x=X, y=pnorm(q=X), type='l', col=5, lwd=2)
legend(1.5, 0.7, c('n = 1', 'n = 2', 'n = 5', 'n = 25', 'dnorm()'), pch=c(1,2,8,0,20), bty='n', col=c(1,2,3,4,5), lty=1)
```

## R语言: 为啥n > 30时dt() -> dnorm()
当n=df>30时，t函数的概率密度函数趋于稳定，无限逼近正态分布.
```{r, echo=FALSE, out.height=350, out.width=800}
layout(matrix(1:2, nrow=1), widths = c(4,4) )  
par(mar=c(5,5,5,1), mex=0.5)
X <- seq(from=-5,to=5,length=51)
dat <- outer(X=X, Y=1:50, function(X,Y)dt(x=X,df=Y))
image(x=X, y=1:50, z=dat, xlab='T-value', ylab='df',main='probability density function')
contour(x=X, y=1:50, z=dat, 
       levels=round(seq(0, 1, length=50), 3),
        add=TRUE, col=4)
grid()
abline(v=0, col=1, lwd=3)
#
dat <- outer(X=X, Y=1:50, function(X,Y)pt(q=X,df=Y))
image(x=X, y=1:50, z=dat,xlab='T-value',ylab='df',main='probability cumulative function')
contour(x=X, y=1:50, z=dat, 
       levels=round(seq(0, 1, length=20),3),
        add=TRUE, col=4)
grid()
abline(v=0, col=1, lwd=3)
```


## 定义: $F$分布
**F分布**: $~设X\sim \chi^2(n)$, $Y\sim \chi^2(m)$, 且$X,Y$相互独立, 则称随机变量$F=\frac{X/n}{Y/m}$为服从自由度为(n,m)的F分布(F-distribution), 称n为第一自由度, 称m为第二自由度, 记为$F\sim F(n,m)$.  

F分布具有如下性质:  
1. $X\sim F(n,m), 则1/X\sim F(m,n)$;  
2. $F_{1-a}(n,m)=\frac{1}{F_a(m,n)}$;  
3. $设X\sim t(n), 则X^2\sim F(1,n)$.  


## 定义: $F$分布    
密度图: df1增大致左松散, df2增大致右松散; 累计图: df1增大致下松散, df2增大致上松散.
```{r, echo=FALSE, out.height=500, out.width=700}
layout(matrix(1:4,nrow=2, byrow=T),widths = c(1,1,1) )
par(mar=c(5,5,1,1), mex=0.5)
curve(df(x, df1=3 , df2=20), 0, 5, col=1,  main=(''), 
      xlab='x', ylab='probability density', 
      xlim=c(0,4), ylim=c(0, 1.5))
curve(df(x, df1=6 , df2=20), 0, 5, col=2, add=T) 
curve(df(x, df1=15, df2=20), 0, 5, col=3, add=T) 
curve(df(x, df1=40, df2=20), 0, 5, col=4, add=T) 
curve(df(x, df1=100, df2=20), 0, 5, col=5, add=T) 
curve(df(x, df1=200, df2=200), 0, 5, col=1, lwd=2, add=T) 
legend(x=1.8, y=1.4, 
       c('df1=3, df2=20','df1=6, df2=20',
        'df1=15, df2=20','df1=40, df2=20',
        'df1=100, df2=20', 'df1=200, df2=200'), 
       lwd=c(1,1,1,1,1,2), col=c(1,2,3,4,5), 
      bty='n', text.col=c(1,2,3,4,5) )
#
curve(df(x, df1=20 , df2=3), 0, 5, col=1, main=(''), 
       xlab='x', ylab='probability density', 
     xlim=c(0,4), ylim=c(0, 1.5)) 
curve(df(x, df1=20 , df2=6), 0, 5, col=2, add=T) 
curve(df(x, df1=20, df2=15), 0, 5, col=3, add=T) 
curve(df(x, df1=20, df2=40), 0, 5, col=4, add=T) 
curve(df(x, df1=20, df2=100), 0, 5, col=5, add=T) 
curve(df(x, df1=200, df2=200), 0, 5, col=1, lwd=2, add=T) 
legend(x=1.8, y=1.4,
       c('df1=20, df2=3','df1=20, df2=6',
        'df1=20, df2=15','df1=20, df2=40',
        'df1=20, df2=100', 'df1=200, df2=200'), 
       lwd=c(1,1,1,1,1,2), col=c(1,2,3,4,5), 
       bty='n', text.col=c(1,2,3,4,5) )
### ### ### ### ### ### ### ### ### ### ### ### ###
curve(pf(q=x, df1=3 , df2=20), 0, 5, col=1, main=(''), 
      xlab='x', ylab='probability cumulative',
      xlim=c(0,4), ylim=c(0, 1))
curve(pf(q=x, df1=6 , df2=20), 0, 5, col=2, add=T) 
curve(pf(q=x, df1=15, df2=20), 0, 5, col=3, add=T) 
curve(pf(q=x, df1=40, df2=20), 0, 5, col=4, add=T) 
curve(pf(q=x, df1=100, df2=20), 0, 5, col=5, add=T) 
curve(pf(q=x, df1=200, df2=200), 0, 5, col=1, lwd=2, add=T) 
legend(x=1.8, y=0.8, 
       c('df1=3, df2=20','df1=6, df2=20',
         'df1=15, df2=20','df1=40, df2=20',
         'df1=100, df2=20', 'df1=200, df2=200'), 
       lwd=c(1,1,1,1,1,2), col=c(1,2,3,4,5), 
       bty='n', text.col=c(1,2,3,4,5) )
# 
curve(pf(q=x, df1=20 , df2=3), 0, 5, col=1, main=(''), 
      xlab='x', ylab='probability cumulative', 
      xlim=c(0,4), ylim=c(0, 1)) 
curve(pf(q=x, df1=20 , df2=6), 0, 5, col=2, add=T) 
curve(pf(q=x, df1=20, df2=15), 0, 5, col=3, add=T) 
curve(pf(q=x, df1=20, df2=40), 0, 5, col=4, add=T) 
curve(pf(q=x, df1=20, df2=100), 0, 5, col=5, add=T) 
curve(pf(q=x, df1=200, df2=200), 0, 5, col=1, lwd=2, add=T) 
legend(x=1.8, y=0.8, 
       c('df1=20, df2=3','df1=20, df2=6',
        'df1=20, df2=15','df1=20, df2=40',
        'df1=20, df2=100', 'df1=200, df2=200'), 
      lwd=c(1,1,1,1,1,2), col=c(1,2,3,4,5), 
      bty='n', text.col=c(1,2,3,4,5) )
```

## 正态总体均值的假设检验
**单个总体的情况:**   
设总体$X\sim N(\mu,\sigma^2), X_1, X_2,\cdot\cdot\cdot, X_n$是来自总体$X$的样本.  
$H_0: \mu=\mu_0,  H_1: \mu\neq\mu_0$  
`(正态分布:)` 当方差$\sigma^2$已知，当$H_0$为真时，  
$Z=\frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}} \sim N(0,1)$ .   
`(t分布:)` 当方差$\sigma^2$未知，当$H_0$为真时，  
$T=\frac{\bar{X}-\mu_0}{S/\sqrt{n}} \sim t(n-1)$  
> `t.test()`

## 正态总体均值的假设检验
**两个总体的情况:**    
设$X_1, X_2,\cdot\cdot\cdot, X_{n1}$是来自总体$X\sim N(\mu_1,\sigma_1^2)$的样本,$Y_1, Y_2,\cdot\cdot\cdot, Y_{n2}$是来自总体$Y\sim N(\mu_2,\sigma_2^2)$的样本.   
  $H_0: \mu_1=\mu_2,  H_1: \mu_1\neq\mu_2$    
`(正态分布:)`当方差$\sigma_1^2和\sigma_2^2$已知，当$H_0$为真时，$Z=\frac{\bar{X}-\bar{Y}}{\sqrt{\sigma_1^2/n_1 +\sigma_2^2/n_2} }\sim N(0,1)$ .  
`(t分布:)`当方差$\sigma_1^2 = \sigma_2^2 = \sigma^2$未知，$S_1^2和S_2^2$分别是$X$和$Y$的样本方差.当$H_0$为真时， 
$T=\frac{\bar{X}-\bar{Y}}{S_w \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}}$ $\sim t(n_1+n_2-2)$.  
$S_w=\sqrt{\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{N_1+N_2-2}}$   
> `t.test()` 

## 正态总体均值的假设检验
**两个总体的情况:**  
`(t分布:)`当方差$\sigma_1^2 \neq \sigma_2^2$未知，$S_1^2和S_2^2$分别是$X$和$Y$的样本方差.当$H_0$为真时, 
$T=\frac{\bar{X}-\bar{Y}}{S_w \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}} \sim t(\hat{\nu})$.   
$\hat{\nu}=(\frac{S_1^2}{n_1}+\frac{S_2^2}{n_2})^2 / (\frac{(S_1^2)^2}{n_1^2(n_1-1)}+\frac{(S_2^2)^2}{n_2^2(n_2-1)})$  


`(t分布:)` 当$(X_i,Y_i)(i=1,2,\cdot\cdot\cdot,n)$,则令$Z_i=X_i-Y_i(i=1,2,\cdot\cdot\cdot,n)$,对Z做单个总体均值的t检验.  
> `t.test()`




## 正态总体方差的假设检验
**单个总体的情况:**  
设$X_1, X_2,\cdot\cdot\cdot, X_n$是来自总体$X\sim N(\mu,\sigma^2)$的样本.  
$H_0: \sigma^2=\sigma_0^2$,  $H_1:\sigma^2 \neq \sigma_0^2$    
`(`$\chi^2$`分布:)`当均值$\mu$已知, 当$H_0$为真时,  
令$\hat{\sigma}^2=\frac{1}{n}\sum_{i=1}^{n}(X_i-\mu)^2$, 则有$\chi^2=\frac{n\hat{\sigma}^2}{\sigma_0^2}\sim\chi^2(n)$.    
`(`$\chi^2$`分布:)`当均值$\mu$未知, 当$H_0$为真时，  
有$\chi^2=\frac{(n-1)S^2}{\sigma_0^2}$$\sim \chi^2(n-1)$    
> `var.test()`

## 正态总体方差的假设检验
**两个总体的情况:**  
设$X_1, X_2,\cdot\cdot\cdot, X_{n1}$是来自总体$X\sim N(\mu_1,\sigma_1^2)$的样本,  $Y_1, Y_2,\cdot\cdot\cdot, Y_{n1}$是来自总体$Y\sim N(\mu_2,\sigma_2^2)$的样本.   
$H_0: \sigma_1^2=\sigma_2^2,  H_1:\sigma_1^2\neq\sigma_2^2$  
`(`$F$`分布:)` 
当均值$\mu_1与\mu_2$已知, 当$H_0$为真时,        
令$\hat{\sigma}_1^2=\frac{1}{n_1}\sum_{i=1}^{n_1}(X_i-\mu_1)^2$, $\hat{\sigma}_2^2=\frac{1}{n_2}\sum_{i=1}^{n_2}(X_i-\mu_2)^2$,   
则有$F=\frac{\hat{\sigma}_1^2}{\hat{\sigma}_2^2}\sim F(n_1,n_2)$.  
> `var.test()` 


## Pearson拟合优度$\chi^2$检验
假设随机变量X符合分布F，现对X进行n次观察，得到样本$X_1, X_2,  \cdot\cdot\cdot, X_n$.   
令, $H_0: X具有分布F;  H_1: X不具有分布F.$    
将数轴分成m个区间:$I_1=(-\infty, a_1)$, $I_2=[a_1, a_2)$,$\cdot \cdot \cdot$, $I_m=[a_{m-1}, \infty)$.  
则, 理论概率为: $p_i=P\{X\in I_i\}$, $i=1,2,\cdot\cdot\cdot, m$. 记$n_i$为X中落在区间$I_i$内的个数.  
$Pearson的\chi^2$统计量$K=\sum_{i=i}^{m}\frac{(n_i-np_i)^2}{np_i}$.   
Pearson证明，当原假设成立，当$n\to\infty$时,K值分布收敛于$\chi^2(m-1)$分布.  
$p值=P\{\chi^2(m-1)>K\}$. $p值<a时$，拒绝原假设.  
> `chisq.test()`

## 最小二乘法
最小二乘法,通过最小化误差的平方和寻找数据的最佳函数匹配.另外也
有用最小化能量或最大化熵来表达.

**例题:** 某次实验得到了四个数据点 (x,y):(1,6)、(2,5)、(3,7)、(4,10).求最优直线 $y=β_1 + β_2 x$:   
**解:** ${\begin{alignedat}{4}\beta _{1}+1\beta _{2}&&\;=\;&&6&\\\beta _{1}+2\beta _{2}&&\;=\;&&5&\\\beta _{1}+3\beta _{2}&&\;=\;&&7&\\\beta _{1}+4\beta _{2}&&\;=\;&&10&\\\end{alignedat}}$  
最小二乘法采用的手段是尽量使得等号两边的方差最小，即:   
${\begin{aligned}S(\beta _{1},\beta _{2})=&\left[6-(\beta _{1}+1\beta _{2})\right]^{2}+\left[5-(\beta _{1}+2\beta _{2})\right]^{2}\\&+\left[7-(\beta _{1}+3\beta _{2})\right]^{2}+\left[10-(\beta _{1}+4\beta _{2})\right]^{2}.\\\end{aligned}}$

## 最小二乘法 
最小值可以通过对 $S(β_1,β_2)$ 分别求 $β_1$ 和 $β_2$ 的偏导数，然后使它们等于零得到.   
${\frac {\partial S}{\partial \beta _{1}}}=0=8\beta _{1}+20\beta _{2}-56$,
${\frac {\partial S}{\partial \beta _{2}}}=0=20\beta _{1}+60\beta _{2}-154$.   
如此得到有两个未知数的方程组,解得:  
$β_1=3.5$,
$β_2=1.4$;  
也就是说直线 y=3.5+1.4x 是最佳的.


## R语言 最小二乘法
y <- rnorm(1000,0,1)，使用最小二乘法，求最优解mu (y的期望值):
```{r}
set.seed(1)
y <- rnorm(n = 1000, mean = 0, sd = 1)
mean(y)
nlm(f = function(mu){sum((y-mu)^2)}, p = 1)
```

## 矩 
**矩(Moment)** 在实数域上的实函数相对于值c的n阶矩为:
$\mu '_{n}=\int _{{-\infty }}^{\infty }(x-c)^{n}\,f(x)\,dx$.  
**期望(Expectation)** 随机变量的期望定义为其1阶原点矩:  
$E(x)=\int _{{-\infty }}^{\infty }x\,f(x)\,dx$  
**方差(Variance)** 随机变量的方差定义为其2阶中心矩:
$var(x)=\int _{{-\infty }}^{\infty }\left[x-E(x)\right]^{2}\,f(x)\,dx$  
**偏态(Skewness)** 随机变量的偏态定义为其3阶中心矩:
$S(x)=\int _{{-\infty }}^{\infty }[x-E(x)]^{3}\,f(x)\,dx$  
**峰态(Kurtosis)** 随机变量的峰态定义为其4阶中心矩:
$K(x)=\int _{{-\infty }}^{\infty }[x-E(x)]^{4}\,f(x)\,dx$  
**样本矩**  矩常常通过样本矩
$\mu '_{n}\approx {\frac {1}{N}}\sum _{{i=1}}^{{N}}X_{i}^{n}$
来估计.这种方法不需要先估计其概率分布.

## 矩法
矩法是英国K.Pearson在1894年提出的，它的中心思想是大数定律，即用样本据去估计总体距.  
**例题: ** 设总体$X$是区间$[a, b]$上的均匀分布，其中$a,b$是未知参数; $x_1,x_2，···，x_n$是总体的一个样本$x$;用矩法估计参数$a$和$b$.  

**解: ** $E(X)=(a+b)/2$,   
$Var(X)=(b-a)^2/12$;   

$E(x)=1/n \sum_{i=1}^{n}x_i$,     
$var(x)=1/n\sum_{i=1}^{n}(x_i-\bar{x})^2$;  

令$E(X)=E(x)$, $Var(X)=var(x)$,  
则，求得$\hat{a}=E(x)-\sqrt{3 var(x)}$,
$~\hat{b}=E(x)+\sqrt{3 var(x)}$.

## R语言 矩法
y <- rnorm(1000,0,1), 使用矩法, 求最优解mu (y的期望值):
```{r}
set.seed(1)
y <- rnorm(n = 1000, mean = 0, sd = 1)
mean(y)
(mu = sum(y)/length(y))
```

## 极大似然法
极大似然法是英国Fisher在1912年提出的，其思想始于Gauss的误差理论，充分利用总体分布函数的信息，克服了矩法的某些不足.   

**似然函数(likelihood function):** 设总体X的概率密度函数为$f(x;\theta),\theta \in \Theta$是未知参数$X_1,X_2,\cdot\cdot\cdot,X_n$,为来自总体$X$的样本,称$L(\theta;x)=$$L(\theta;x_1,x_2,\cdot\cdot\cdot,x_n)=$$\Pi_{i=1}^{n}f(x_i;\theta)$为$\theta$的似然函数.     

**极大似然估计(maximum likelihood estimation):** 若$\hat{\theta}=\hat{\theta}(X)=\hat{\theta}(X_1,X_2,\cdot\cdot\cdot,X_n)$是一个统计量且满足$L(\hat{\theta}(X);X)=\underset{\theta \in \Theta}{sup}L(\theta;X)$,则称$\hat{\theta}(X)$为$\theta$的极大似然估计,简记为MLE.     

用极大似然估计来估计参数的方法称为极大似然法.

## 极大似然法
**例题: ** 设总体$X$是区间$[a, b]$上的均匀分布，其中$a,b$是未知参数; $x_1,x_2,···,x_n$是总体的一个样本$x$; 用极大似然法估计参数$a$和$b$.   

**解: ** 
样本$x$的似然函数为$L(a,b;x)=1/(b-a)^n$,  
$(其中a\leq x_i\leq b, i=1,2,\cdot\cdot\cdot,n)$.    

当$a=min\{x_1,x_2,\cdot\cdot\cdot,x_n\}=x_{(1)}$,   
且$b=max\{x_1,x_2,\cdot\cdot\cdot,x_n\}=x_{(n)}$时,   
似然值$L(a,b;x)$将达到最大.    

因此，$\hat{a}=x_{(1)}$, $\hat{b}=x_{(n)}$.

## R语言: 极大似然法
y <- rnorm(1000,0,1)，使用极大似然法，求最优解mu (y的期望值):
```{r}
set.seed(1)
y <- rnorm(n = 1000, mean = 0, sd = 1)
mean(y)
nlm(f = function(mu){-sum(dnorm(x=y, mean=mu, sd=1, log=T))}, p = 1)
```

## 方差分析
方差分析应具备三个条件: 

1. 可加性。假设模型是线性可加模型，每个处理效应与随机误差是可以叠加的，即：$x_{ij}=\mu+\alpha_i+\xi_{ij}$; $其中\sum_{i=1}^rn_i\alpha_i=0$。

2. 独立正态性。随机误差应当服从正态分布，而且相互独立。  
即$\xi_{ij}\sim N(0,\sigma^2)$,且相互独立。

3. 方差齐性。不同处理间的方差是一致的，即满足假设$H_0:\sigma_1^2=\sigma_2^2=\cdot\cdot\cdot=\sigma_r^2$.  

## 单因素方差分析
若$x_{ij}=\mu+\alpha_i+\xi_{ij}.$   
$x_{i}\sim N(\mu_i,\sigma^2),~~$
$\mu=E(x_{ij}),$   
$\sum_{i=1}^rn_i\alpha_i=0,~~$ 
$\xi_{ij}\sim N(0,\sigma^2).$   
可用方差分析来研究因素A对试验指标影响的大小.
$H_0: a_1=a_2=\cdot\cdot\cdot=a_r=0,$    
$H_1: a_1,a_2,\cdot\cdot\cdot,a_r不全为零.$  

$S_T=S_A+S_E;$  
$S_A=\sum_{i=1}^r\sum_{j=1}^{n_i}\alpha_i^2,~~$ 
$S_E=\sum_{i=1}^r\sum_{j=1}^{n_i}\xi_{ij}^2;$ 
$\frac{S_E}{\sigma^2} \sim \chi^2(n-r),~~$
$\frac{S_A}{\sigma^2} \sim \chi^2(r-1).$   
当$H_0$成立: $F=\frac{S_A/(r-1)}{S_E/(n-r)}\sim F(r-1,n-r).$

## 双因素方差分析
若$x_{ij}=\mu+\alpha_i+\beta_j+\xi_{ij};~~$
$x_{ij}\sim N(\mu_{ij},\sigma^2),$  
$\mu=E(x_{ij}),$
$\sum_{i=1}^r\alpha_i=0,$ 
$\sum_{j=1}^s\beta_j=0,$
$\xi_{ij}\sim N(0,\sigma^2).$  
可用方差分析来研究因素A和因素B对试验指标影响的大小。    

$H_{01}: \alpha_1=\alpha_2=\cdot\cdot\cdot=\alpha_r=0,$    
$H_{02}: \beta_1=\beta_2=\cdot\cdot\cdot=\beta_r=0.$   
$S_T=S_A+S_B+S_E;~~~$ 
$S_A=\sum_{i=1}^r\sum_{j=1}^{n_i}\alpha_i^2,$ 
$S_B=\sum_{i=1}^r\sum_{j=1}^{n_i}\beta_j^2,~~$ 
$S_E=\sum_{i=1}^r\sum_{j=1}^{n_i}\xi_{ij}^2;$
$\frac{S_A}{\sigma^2} \sim \chi^2(r-1),~~$
$\frac{S_E}{\sigma^2} \sim \chi^2(r-1)(s-1);$

当$H_{01}$成立:$F_A=\frac{S_A/(r-1)}{S_E/[(r-1)(s-1)]}$$\sim F(r-1,(r-1)(s-1))$.   
当$H_{02}$成立:$F_B=\frac{S_B/(s-1)}{S_E/[(r-1)(s-1)]}$$\sim F(s-1,(r-1)(s-1))$.

## 回归分析
回归分析研究的主要问题是:   
1. 确定$Y$与$X_1,X_2,\cdot\cdot\cdot,X_p$间的定量关系表达式，这种表达式称为回归方程;   
2. 对求得的回归方程的可信度进行检验;   
3. 判断自变量$X_j(j=1,2,\cdot\cdot\cdot,p)$对$Y$有无影响;   
4. 利用所求得的回归方程进行预测和控制.   

## 一元线性回归
**已知观测数据点:**$(x_1,y_1),(x_2,y_2),\cdot\cdot\cdot,(x_n,y_n)$.  

**一元线性回归模型:** $~~y_i=\beta_0+\beta_1x_i+\xi_i,~~$  
其中$i=1,2,\cdot\cdot\cdot,n,~~$ $E(\xi_i)=0,~~$
$var(\xi_i)=\sigma^2.$   

**最小二乘法估计参数:** $Q(\beta_0,\beta_1)=\sum_{i=1}^n(y_i-\beta_0-\beta_1x_i)^2,$$~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~$
$Q(\hat{\beta}_0,\hat{\beta}_1)=\underset{\beta_0,\beta_1}{min}Q(\beta_0,\beta_1).$  

**解得:** $\hat{\beta_1}=\frac{\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}=\frac{S_{xy}}{S_{xx}},~~$
$\hat{\beta_0}=\bar{y}-\hat{\beta}_1\bar{x};$

$\hat{\sigma}^2=\frac{\sum_{i=1}^n(y_i-\hat{\beta}_0-\hat{\beta}_1x_i)^2}{n-2};$   

$sd(\hat{\beta}_0)=\hat{\sigma}\sqrt{\frac{1}{n}+\frac{\bar{x}^2}{S_{xx}}},~~$
$sd(\hat{\beta}_1)=\frac{\hat{\sigma}}{\sqrt{S_{xx}}}.$


## 一元线性回归的显著性检验
假设检验:$H_0: \beta_1=0,  H_1:\beta_1\neq 0$  
1. t分布.  
当$H_0$成立时,统计量
$T=\frac{\hat{\beta}_1}{sd(\hat{\beta}_1)}$$=\frac{\hat{\beta}_1\sqrt{S_{xx}}}{\hat{\sigma}}$$\sim t(n-2).$  
2. F分布.   
当$H_0$成立时，统计量
$F=\frac{\hat{\beta}_1^2S_{xx}}{\hat{\sigma}^2}\sim F(1,n-2)$

## 一元线性回归的相关系数
$y_i=\bar{\beta}_0+\hat{\beta}_1x_i+\xi_i$$=\bar{y}+\hat{\beta}_1x_i+\xi_i$  

**相关系数平方(squared correlation coefficient ):**$~~~ R^2=\frac{S_{xy}^2}{S_{xx}S_{yy}}=\frac{[\sum_{i=1}^n(x_i-\bar{x})(y_i-\bar{y})]^2}{\sum_{i=1}^n(x_i-\bar{x})^2\sum_{i=1}^n(y_i-\bar{y})^2}$   

**模型决定系数(determination coefficient):**$~~~ R^2=\frac{SS_R}{SS_T}=\frac{\sum_{i=1}^n(\hat{\beta}_1x_i)^2}{\sum_{i=1}^n(\hat{\beta}_1x_i+\xi_i)^2}$  


## 相关系数平方 与 模型决定系数 
```{r}
set.seed(1)
Xi <- runif(n=1000,min=-1,max=1)
sigma <- rnorm(1000)
Yi <- 20 + 3*Xi + sigma ##
Sxy <- sum( (Xi-mean(Xi)) * (Yi-mean(Yi)) )
Sxx <- sum( (Xi-mean(Xi))^2 )
Syy <- sum( (Yi-mean(Yi))^2 )
( R2.pearson <- Sxy^2 / (Sxx * Syy) )
coef <- lm(Yi~Xi)$coefficients
SSr <- sum( (coef[2] *Xi)^2 )
SSt <- sum( (Yi- coef[1])^2 )
( R2.regression <- SSr / SSt )
```

## 一元线性回归参数的区间估计
由$\beta_0$与$\beta_1$的统计性质可知:     
$T_i=\frac{\hat{\beta}_i-\beta_i}{sd(\hat{\beta}_i)}\sim t(n-2),$$~~i=0,1$  

对给定的置信水平1-$\alpha$,则有:  
$p\{|\frac{\hat{\beta_i}-\beta_i}{sd(\hat{\beta_i})}|\leq t_{\alpha/2}(n-2)\}=1-\alpha,~~~ i=0,1$

因此，$\beta_i(i=0,1)$的区间估计为:  
$[\hat{\beta_i}-sd(\hat{\beta_i})t_{\alpha/2}(n-2),~\hat{\beta_i}+sd(\hat{\beta_i})t_{\alpha/2}(n-2)]$

## 多元线性回归
**已知:** $(x_{i1}, x_{i2}, \cdot\cdot\cdot, x_{ip}, y_i)$是$(X_1, X_2,\cdot\cdot\cdot, X_p, Y)$的n次独立观测值.其中$i=1,2,\cdot\cdot\cdot,n.$ 

**多元线性模型:** $Y=X\beta+\xi;$   
$y_i=\beta_0+\beta_1x_{i1}+\cdot\cdot\cdot+\beta_px_{ip}+\xi_i,$  
$\xi_i\sim N(0,\sigma^2).$

**最小二乘法估计参数:** $Q(\beta)=(Y-X\beta)^T(Y-X\beta),$
$~~~~~~~~~~~~~~~~~~~~~~~~~~~\hat{\beta}=(X^TX)^{-1}X^TY,$ 
$\hat{Y}=\hat{\beta_0}+\hat{\beta_1}X_i+\cdot\cdot\cdot+\hat{\beta}_pX_p.$  

**解得:** $\hat{\xi}=Y-X\hat{\beta},~~$
$\hat{\sigma}^2=\hat{\xi}^T\hat{\xi}/(n-p-1),$
$sd(\hat{\beta_i})=\hat{\sigma}\sqrt{c_{ii}},~~$
$i=0,1,\cdot\cdot\cdot,p.$  
其中$c_{ii}$是$C=(X^TX)^{-1}对角线上第i个元素.$

## 多元线性回归的显著性检验
**1. 回归系数的显著性检验.**   
$H_{j0}: \beta_j=0,  H_1:\beta_j\neq 0.$   
其中$j=0,1,\cdot\cdot\cdot,p.$   
当$H_{j0}$成立时，统计量$T_j=\frac{\hat{\beta_j}}{\hat{\sigma}\sqrt{c_{jj}}}\sim t(n-p-1),$  
其中$j=0,1,\cdot\cdot\cdot,p.$
$c_{jj}$是$C=(X^TX)^{-1}对角线上第j个元素。$   

**2. 回归方程的显著性检验.**  
$H_0:\beta_0=\beta_1=\cdot\cdot\cdot=\beta_p=0,$ $H_1:\beta_0,\beta_1,\cdot\cdot\cdot,\beta_p不全为0.$    
当$H_0$成立时,统计量$F=\frac{SS_R/p}{SS_E/(n-p-1)}\sim F(p,n-p-1),$  
其中$SS_R=\sum_{i=1}^n(\hat{y_i}-\bar{y})^2,$
$SS_E=\sum_{i=1}^n(y-\hat{y_i})^2.$

## 多元线性回归的决定系数
$y_i=\bar{\beta}_0+\hat{\beta}X_i+\xi$$=\bar{y}+\hat{\beta}X_i+\xi=\hat{y}_i+\xi$    

**回归模型决定系数:**$~~~$$R^2=\frac{SS_R}{SS_T}=\frac{\sum_{i=1}^n(\hat{\beta}X_i)^2}{\sum_{i=1}^n(\hat{\beta}X_i+\xi)^2}$  

回归平方和: $SS_R=\sum_{i=1}^n(\hat{y_i}-\bar{y})^2=\sum_{i=1}^n(\hat{\beta}X_i)^2,$   
残差平方和: $SS_E=\sum_{i=1}^n(y_i-\hat{y_i})^2=\sum_{i=1}^n \xi^2,$   
总体平方和: $SS_T=\sum_{i=1}^n(y_i-\bar{y})^2=\sum_{i=1}^n(\hat{\beta}X_i+\xi)^2,$  
$~~~~~~~~~~~~~~~~~~~~$$SS_T=SS_R+SS_E.$  

## 多元线性回归的参数区间估计

由$\beta$的统计性质可知:  
$T_i=\frac{\hat{\beta}_i-\beta_i}{sd(\hat{\beta}_i)}$$\sim t(n-p-1),$$其中i=0,1,\cdot\cdot\cdot,p.$  
因此，$\beta_i(i=0,1,\cdot\cdot\cdot,p)$的区间估计为:  
$[\hat{\beta}_i-sd(\hat{\beta}_i)t_{\alpha/2}(n-p-1), \hat{\beta}_i+sd(\hat{\beta}_i)t_{\alpha/2}(n-p-1)].$  

##  完

