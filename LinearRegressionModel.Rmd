---
title: "线性模型的假设条件"
author: "wangbinzjcc@qq.com"
date: "Wednesday, January 28, 2015"
output: ioslides_presentation
---

## 一元线性模型是所有模型之母。
the linear regression model is the ‘mother of all models’ .

$Y_i = \alpha + \beta X_i + \epsilon_i,$  where $\epsilon_i \sim N(0,  \sigma^2)$ and independent.

## 线性模型的假设条件：  
1. 误差项是否满足独立性、等方差性、正态性；  
2. 选择线性模型是否合适；  
3. 是否存在异常样本；  
4. 回归模型是否具备稳健型，回归结果是否过重依赖某些样本；  
5. 是否存在多重共线性问题，自变量之间是否存在高度相关；  

## 为什么独立性如此重要？  
1. 回归系数估计基于独立同分布的随机变量，如果数据不独立(假重复)，回归系数会过分依赖假重复数据，回归系数的估计不准。  
2. 回归系数显著性检验，如果数据不独立，随机变量实际自由度会小于计算使用自由度，会引起显著性检验的误差。  

## 为什么等方差性如此重要？  
1. 回归系数估计，如果方差不齐，回归系数的估计将会过分依赖来自方差较大总体的变量数据，回归系数的估计不准。  
2. 回归系数显著性检验，如果方差不齐，无法估计总体方差，统计值的计算不准确。  
3. 预测的精确度没法确定。     

## 为什么正态性如此重要？  
1. 某些参数估计的算法依赖于正态分布。  

## 为什么不能自变量共线、过分依赖某些样本？  
1.  会使模型的稳定性和可预测性下降。   




















